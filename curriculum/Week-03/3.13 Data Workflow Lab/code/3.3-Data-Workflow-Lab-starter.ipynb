{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Workflow Lab 1\n",
    "\n",
    "We want to look and see if an airport has limited, moderate, or severe delays. \n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "* Practice datatype conversion\n",
    "* Practice filling in missing values with either 0 or the average in the column\n",
    "* Practice categorical data techniques\n",
    "* Transform data into usable quantities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd \n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import sklearn as sk \n",
    "from scipy.stats import pearsonr, normaltest\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_raw = pd.read_csv(\"airport_operations.csv\")\n",
    "df = df_raw.dropna() \n",
    "print df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data\n",
    "\n",
    "Let's practice our data cleaning skills on the  dataset. If you don't remember how to do any of these tasks, look back at your work from the previous weeks or search the internet. There are many blog articles and Stack Overflow posts that cover these topics.\n",
    "\n",
    "What are the risks and assumptions of our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Delete Unecessary Data. What might not be useful here? How can we tell? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine and Mine the Data\n",
    "\n",
    "Some airports have improved their metrics over time, some have not. We want to target airports who metrics are not getting better - IE: Their percent on time departures has not improved. As a benchmark, let's qualify \"good\" performance for an arrival or departure metric as being >= .75\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine which airports have not improved in their overall performance. To measure \"overall\" performance \n",
    "#look at the various metrics in relation to each other \n",
    "\n",
    "\n",
    "\n",
    "# What are airports with good performance doing in particular? What are the characteristics of their metrics? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Check for Unique Values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Does the dataset follow a normal distribution? How can you tell? \n",
    "normaltest()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Look at correlations in the data: \n",
    "\n",
    "\n",
    "# Get the correlation between numeric columns to look over them with seaborn's heatmap.\n",
    "df_corrs = df[features_here].corr()\n",
    "\n",
    "# Make a figure and get the axis out, setting the figsize to be decently large.\n",
    "fig = plt.figure(figsize=(14,12))\n",
    "ax = fig.gca()\n",
    "\n",
    "# Make a heatmap of the correlations with the mask and axis\n",
    "ax = sns.heatmap(df_corrs, ax=ax)\n",
    "\n",
    "# Make the label ticks bigger\n",
    "ax.xaxis.set_tick_params(labelsize=12)\n",
    "ax.yaxis.set_tick_params(labelsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute New Columns and Tables\n",
    "\n",
    "Since we're trying to predict airport delays, we'll want to compute some intermediate data. There are a lot of ways to do thisand good use of pandas is crucial. For example, we may want to know categorize each airport as having significant, moderate, or limited delays. You can compare your calculated fields with data from the \"cancellations\" set as a benchmark, for instance. \n",
    "\n",
    "Make sure to retain other variables that we'll want to use to build our models.\n",
    "\n",
    "Bonus tasks:\n",
    "* Restrict your attention to airports in the same region and do a comparative analysis based on region. The \"airports\" dataset contains information about location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proceed with any calculations that you need for your models, such as grouping\n",
    "sales by location, most common departure/arrival delay, etc. Once you have finished adding columns, be sure to save the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute more things\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your model\n",
    "Time to model! Let's build a predictive regression model to predict whether an airport has significant, moderate, or limited delays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune your Model utilizing gradient descent for optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a loss function of your choice and minimize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
